[
  {
    "objectID": "lab3.html",
    "href": "lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Q1.\n\nTake a moment to reflect on the value of open data:\nHow does easy access to historical and real-time environmental data shape our understanding of climate trends, resource management, and public health? What happens when this data disappears or becomes inaccessible? The role of independent archiving and collaborative stewardship has never been more critical in ensuring scientific progress and accountability.\n\nWhen we can access historical and real-time data, we’re better able to draw connections between previous conditions and the present to identify trends over time. We can see how present observations fit with previous data, which is the most important evidence that climate change is happening. When these data are accessible to everyone, we can hold our leaders accountable for the decisions they make, which are supposed to be on behalf of the public. Natural resource management is a very rough science that can be heavily influenced by policies, so access to data over time is crucial for holding agencies accountable in processes like the National Environmental Policy Act, where the public has a chance to influence agency actions, or the actions of any major actor on natural resources, or to identify trends over time that have multiple influences. When the data disappear or become inaccessible, people can get away with lying to support ulterior motives and decision makers can make choices with catastrophic consequences.\n\n\n\n\nQ2.Daily Summary\n\n\nConditions to Meet for CO Public Health\nFor More than 100 new cases in Colorado per 100,000 residents over the past 14 days, report also:\n\ncumulative cases in the 5 worst counties\ntotal NEW cases in the 5 worst counties\nA list of safe counties\nA text report describing the total new cases,\ntotal cumulative cases, and number of safe counties.\n\n\nSteps Q2\n\nStart by reading in the data from the NY-Times URL with read_csv (make sure to attach the tidyverse)\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(flextable)\n\n\nAttaching package: 'flextable'\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\ndata = read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\n\nRows: 2502832 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): county, state, fips\ndbl  (2): cases, deaths\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nCreate an object called my.date and set it as “2022-02-01” - ensure this is a date object:. Create a object called my.state and set it to “Colorado”.\n\n\ntxt &lt;- \"2022-02-01\"\nclass(txt)\n\n[1] \"character\"\n\nmy.date &lt;- as.Date(txt)\nclass(my.date)\n\n[1] \"Date\"\n\n\n\nmy.state &lt;- as.character(\"Colorado\")\nclass(my.state)\n\n[1] \"character\"\n\n\n3.The URL based data read from Github is considered our “raw data”. Remember to always leave “raw-data-raw” and to generate meaningful subsets as you go.\nStart by making a subset that limits (filter) the data to Colorado and add a new column (mutate) with the daily new cases using diff/lag by county (group_by). Do the same for new deaths as well.\n\nlibrary(knitr)\n\nco_covid &lt;- data %&gt;% \n  filter(state == \"Colorado\") %&gt;% \n  group_by(county) %&gt;% \n  mutate(case_lag = lag(cases, n = 1)) %&gt;% \n  mutate(new_cases = cases-case_lag) %&gt;% \n  mutate(death_lag = lag(deaths, n = 1)) %&gt;%\n  mutate(new_deaths = deaths - death_lag) %&gt;% \n  arrange(date) %&gt;% \n  ungroup()\n\nQ2. Using your subset, generate (2) tables. The first should show the 5 counties with the most CUMULATIVE cases, and the second should show the 5 counties with the most NEW cases. Remember to use your my.date object as a proxy for today’s date:\n\n\nColorado: Top 5 counties with the most cumulative cass\n\n#five counties with the most cumulative cases\n\nco_covid %&gt;% \n   filter(date == my.date) %&gt;% \n  select(county, cases) %&gt;%\n  slice_max(order_by = cases, n = 5) %&gt;% \n  kable(caption = \"Five Colorado counties with the most cumulative COVID cases as of February 1st, 2022\")\n\n\nFive Colorado counties with the most cumulative COVID cases as of February 1st, 2022\n\n\ncounty\ncases\n\n\n\n\nEl Paso\n170673\n\n\nDenver\n159022\n\n\nArapahoe\n144255\n\n\nAdams\n126768\n\n\nJefferson\n113240\n\n\n\n\n\n\n\nColorado: top 5 counties with the most new cases\n\n#five counties with the most new cases\n\nco_covid %&gt;% \n  filter(date == my.date) %&gt;% \n  select(county, new_cases) %&gt;%\n  slice_max(order_by = new_cases, n = 5, na_rm = TRUE) %&gt;% kable(caption = \"Five Colorado counties with the most new COVID cases on Febrary 1st, 2022\")\n\n\nFive Colorado counties with the most new COVID cases on Febrary 1st, 2022\n\n\ncounty\nnew_cases\n\n\n\n\nEl Paso\n630\n\n\nArapahoe\n401\n\n\nDenver\n389\n\n\nAdams\n326\n\n\nJefferson\n291\n\n\n\n\n\nYour tables should have clear column names and descriptive captions.\n\n\n\nQ3: Normalizing Data\nRaw count data can be deceiving given the wide range of populations in Colorado countries. To help us normalize data counts, we need supplemental population data to be added. Population data is offered by the Census and can be found here. Please read in this data.\nHow FIPS codes are structured - The number of digits in a FIPS code depends on the level of geography - State FIPS codes have two digits - County FIPS codes have five digits, with the first two digits representing the state FIPS code\n\nConvert the STATE numeric into a character forced to 2 digits with a leading 0 (when needed)\nConvert the COUNTY numeric into a character forced to 3 digits with leading 0’s (when needed)\nCreate a FIP variable the STATE numeric into a character forced to 2 digits with a leading 0 (when needed)\n\n\npop_url &lt;- 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv'\n\npop = read_csv(pop_url)\n\nRows: 3195 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): SUMLEV, STATE, COUNTY, STNAME, CTYNAME\ndbl (62): REGION, DIVISION, ESTIMATESBASE2020, POPESTIMATE2020, POPESTIMATE2...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# In this part, we're adding the correct amount of digits to each component of the fips data, which in this table was separated. We want to merge the state and county column to get a complete county fip, which will be the overlapping we make our join table off of\n\npop &lt;- pop |&gt;\n  mutate(STATE = as.numeric(STATE), COUNTY = as.numeric(COUNTY))|&gt;\n  mutate(fips = paste0(sprintf(\"%02d\",STATE),sprintf(\"%03d\", COUNTY)))\n\n\nGiven the above URL, and guidelines on string concatenation and formatting, read in the population data and (1) create a five digit FIP variable and only keep columns that contain “NAME” or “2021” (remember the tidyselect option found with ?dplyr::select). Additionally, remove all state level rows (e.g. COUNTY FIP == “000”)\n\n1\n\nlibrary(stringr)\n\npop21 &lt;- pop %&gt;%\n  select(fips, contains(\"2021\"), contains(\"NAME\")) %&gt;%\nfilter(!str_ends(fips, \"000\"))\n\n\nNow, explore the data … what attributes does it have, what are the names of the columns? Do any match the COVID data we have? What are the dimensions… In a few sentences describe the data obtained after modification:\n\n\nnames(pop21)\n\n [1] \"fips\"                  \"POPESTIMATE2021\"       \"NPOPCHG2021\"          \n [4] \"BIRTHS2021\"            \"DEATHS2021\"            \"NATURALCHG2021\"       \n [7] \"INTERNATIONALMIG2021\"  \"DOMESTICMIG2021\"       \"NETMIG2021\"           \n[10] \"RESIDUAL2021\"          \"GQESTIMATES2021\"       \"RBIRTH2021\"           \n[13] \"RDEATH2021\"            \"RNATURALCHG2021\"       \"RINTERNATIONALMIG2021\"\n[16] \"RDOMESTICMIG2021\"      \"RNETMIG2021\"           \"STNAME\"               \n[19] \"CTYNAME\"              \n\ndim(pop21)\n\n[1] 3144   19\n\nnrow(pop21)\n\n[1] 3144\n\nstr(pop21)\n\ntibble [3,144 × 19] (S3: tbl_df/tbl/data.frame)\n $ fips                 : chr [1:3144] \"01001\" \"01003\" \"01005\" \"01007\" ...\n $ POPESTIMATE2021      : num [1:3144] 59203 239439 24533 22359 59079 ...\n $ NPOPCHG2021          : num [1:3144] 288 6212 -436 171 -28 ...\n $ BIRTHS2021           : num [1:3144] 686 2337 270 240 654 ...\n $ DEATHS2021           : num [1:3144] 696 2948 390 325 875 ...\n $ NATURALCHG2021       : num [1:3144] -10 -611 -120 -85 -221 -49 -70 -593 -200 -188 ...\n $ INTERNATIONALMIG2021 : num [1:3144] 15 105 0 1 9 1 5 12 22 7 ...\n $ DOMESTICMIG2021      : num [1:3144] 242 6972 -313 254 141 ...\n $ NETMIG2021           : num [1:3144] 257 7077 -313 255 150 ...\n $ RESIDUAL2021         : num [1:3144] 41 -254 -3 1 43 4 5 86 21 2 ...\n $ GQESTIMATES2021      : num [1:3144] 484 3351 2248 1994 616 ...\n $ RBIRTH2021           : num [1:3144] 11.62 9.89 10.91 10.78 11.07 ...\n $ RDEATH2021           : num [1:3144] 11.8 12.5 15.8 14.6 14.8 ...\n $ RNATURALCHG2021      : num [1:3144] -0.169 -2.585 -4.848 -3.816 -3.74 ...\n $ RINTERNATIONALMIG2021: num [1:3144] 0.254 0.4443 0 0.0449 0.1523 ...\n $ RDOMESTICMIG2021     : num [1:3144] 4.1 29.5 -12.65 11.4 2.39 ...\n $ RNETMIG2021          : num [1:3144] 4.35 29.95 -12.65 11.45 2.54 ...\n $ STNAME               : chr [1:3144] \"Alabama\" \"Alabama\" \"Alabama\" \"Alabama\" ...\n $ CTYNAME              : chr [1:3144] \"Autauga County\" \"Baldwin County\" \"Barbour County\" \"Bibb County\" ...\n\nglimpse(pop21)\n\nRows: 3,144\nColumns: 19\n$ fips                  &lt;chr&gt; \"01001\", \"01003\", \"01005\", \"01007\", \"01009\", \"01…\n$ POPESTIMATE2021       &lt;dbl&gt; 59203, 239439, 24533, 22359, 59079, 10143, 18890…\n$ NPOPCHG2021           &lt;dbl&gt; 288, 6212, -436, 171, -28, -86, -135, -565, -163…\n$ BIRTHS2021            &lt;dbl&gt; 686, 2337, 270, 240, 654, 111, 227, 1250, 392, 2…\n$ DEATHS2021            &lt;dbl&gt; 696, 2948, 390, 325, 875, 160, 297, 1843, 592, 4…\n$ NATURALCHG2021        &lt;dbl&gt; -10, -611, -120, -85, -221, -49, -70, -593, -200…\n$ INTERNATIONALMIG2021  &lt;dbl&gt; 15, 105, 0, 1, 9, 1, 5, 12, 22, 7, 20, 1, 0, -1,…\n$ DOMESTICMIG2021       &lt;dbl&gt; 242, 6972, -313, 254, 141, -42, -75, -70, -6, 28…\n$ NETMIG2021            &lt;dbl&gt; 257, 7077, -313, 255, 150, -41, -70, -58, 16, 29…\n$ RESIDUAL2021          &lt;dbl&gt; 41, -254, -3, 1, 43, 4, 5, 86, 21, 2, 18, 7, 8, …\n$ GQESTIMATES2021       &lt;dbl&gt; 484, 3351, 2248, 1994, 616, 1578, 285, 5407, 856…\n$ RBIRTH2021            &lt;dbl&gt; 11.615503, 9.888589, 10.908650, 10.775136, 11.06…\n$ RDEATH2021            &lt;dbl&gt; 11.78483, 12.47392, 15.75694, 14.59133, 14.80717…\n$ RNATURALCHG2021       &lt;dbl&gt; -0.1693222, -2.5853351, -4.8482890, -3.8161941, …\n$ RINTERNATIONALMIG2021 &lt;dbl&gt; 0.25398330, 0.44428836, 0.00000000, 0.04489640, …\n$ RDOMESTICMIG2021      &lt;dbl&gt; 4.0975973, 29.5007468, -12.6459537, 11.4036860, …\n$ RNETMIG2021           &lt;dbl&gt; 4.3515806, 29.9450352, -12.6459537, 11.4485824, …\n$ STNAME                &lt;chr&gt; \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Ala…\n$ CTYNAME               &lt;chr&gt; \"Autauga County\", \"Baldwin County\", \"Barbour Cou…\n\n#my computer can't do skimr()\n\nintersect(names(pop21), names(co_covid))\n\n[1] \"fips\"\n\n\n\nThere are 3144 rows and 19 columns in pop21. There are demographic data like births, deaths, and migration. As of right now, the only columns that intersect are fips because I created that column in the population dataset. Both datasets have county names, state names. While pop21 has total deaths, co_covid just has COVID deaths.What I’m trying to figure out is how a join will happen if the number of rows for my population and covid data don’t match up. I found out that whatever dataset you specify for the join is the number of columns the function will output.\n\n3 What is the range of populations seen in Colorado counties in 2021:\n\nCOpop21 &lt;- pop21 %&gt;% \nfilter(STNAME == \"Colorado\") %&gt;%  mutate(state = STNAME, county = CTYNAME) %&gt;% \n  select(-CTYNAME, -STNAME) %&gt;%\n  mutate(county = str_replace(county, \" County\", \"\"))\n  \nrange(COpop21$POPESTIMATE2021)\n\n[1]    741 737287\n\n\n\nIn Colorado, county populations range from 741 to 737287.\nJoin the population data to the Colorado COVID data and compute the per capita cumulative cases, per capita new cases, and per capita new deaths:\n\n\nco_covid &lt;- co_covid %&gt;% \n  arrange(county)\n\nco_covid_pop &lt;- left_join(co_covid, COpop21, by = NULL) %&gt;%\n  group_by(county) %&gt;% \n  mutate(percap_cumulative = cases/POPESTIMATE2021) %&gt;% \n  mutate(percap_new_cases = new_cases/POPESTIMATE2021) %&gt;% \n  mutate(percap_new_deaths = new_deaths/POPESTIMATE2021) %&gt;% \nungroup()\n\nJoining with `by = join_by(county, state, fips)`\n\n\n\nGenerate (2) new tables. The first should show the 5 counties with the most cumulative cases per capita on 2021-01-01, and the second should show the 5 counties with the most NEW cases per capita on the same date. Your tables should have clear column names and descriptive captions.\n\n\nFirst Table\n\nco_covid_pop %&gt;%\n  mutate(date_char = as.character(date)) %&gt;% \nselect(percap_cumulative, county, date_char, cases) %&gt;% \n  group_by(date_char) %&gt;%\n  arrange(date_char) %&gt;% \n  filter(date_char == \"2021-01-01\")  %&gt;% slice_max(order_by = percap_cumulative, n = 5) %&gt;%\n  flextable(col_keys = c(\"percap_cumulative\", \"cases\", \"county\")) %&gt;%  # \n  width(width = 0.75) %&gt;%\n  height(height = 0.25) %&gt;%\n  set_header_labels(\n    cases = \"Cumulative Cases\",\n    percap_cumulative = \"Cases per Capita\",\n    county = \"County\"\n  ) %&gt;%  \n   set_caption(\"Top 5 Counties by Cumulative COVID Cases per Capita on Jan 1, 2021\") %&gt;% \n  theme_booktabs() \n\nCases per CapitaCumulative CasesCounty0.289450741,660Crowley0.210900921,126Bent0.154670093,249Logan0.14306596783Lincoln0.095070784,681Fremont\n\n\n\n\nSecond Table\n\nco_covid_pop %&gt;%\n  mutate(date_char = as.character(date)) %&gt;% \nselect(percap_new_cases, county, date_char, new_cases, cases) %&gt;% \n  group_by(date_char) %&gt;%\n  arrange(date_char) %&gt;% \n  filter(date_char == \"2021-01-01\")  %&gt;% slice_max(order_by = percap_new_cases, n = 5) %&gt;% \nungroup() %&gt;% \n  flextable(col_keys = c(\"percap_new_cases\", \"new_cases\", \"county\")) %&gt;%\n  width(width = 0.75) %&gt;%\n  height(height = 0.25) %&gt;%\n  set_header_labels(\n    percap_new_cases = \"New Cases per Capita\",\n    new_cases = \"New Cases\",\n    county = \"County\"\n  ) %&gt;%  \n   set_caption(\"Top 5 Counties by New COVID Cases per Capita on Jan 1, 2021\") %&gt;% \n  theme_booktabs()\n\nNew Cases per CapitaNew CasesCounty0.01666978889Bent0.0034393818Sedgwick0.00263411252Chaffee0.00226678313Crowley0.0021528532Mineral\n\n\n#Q4. Rolling Thresholds National\nA rolling threshold is a predefined value that changes as time advances.\nFilter the merged COVID/Population data to only include the last 14 days. Remember this should be a programmatic request and not hard-coded. Then, use the group_by/summarize paradigm to determine the total number of new cases in the last 14 days per 100,000 people. Print a table of the top 5 counties, and, report the number that meet the watch list condition: “More than 100 new cases per 100,000 residents over the past 14 days…”\n\n\nTotal number of new cases, last 14 days for each county\n\ndata &lt;- data %&gt;% \narrange(county, date)\n\n# finding the new cases nationally\ndata &lt;- data %&gt;%\narrange(state, county, date) %&gt;%\n  group_by(county) %&gt;% \n  mutate(case_lag = lag(cases, n = 1, order_by = county)) %&gt;% \n  mutate(death_lag = lag(deaths, n = 1, order_by = county)) %&gt;% \n  mutate(new_cases = cases-case_lag) %&gt;% \n  mutate(new_deaths = deaths - death_lag) %&gt;%\n  ungroup()\n\n#changing population, state, and county column data to overlap with covid data for a join\npop &lt;- pop %&gt;% \n  select(fips, contains(\"202\"), contains(\"NAME\")) %&gt;%\nfilter(!str_ends(fips, \"000\")) %&gt;% \nmutate(state = STNAME, county = CTYNAME) %&gt;% \n  select(-CTYNAME, -STNAME) %&gt;%\n  mutate(county = str_replace(county, \" County\", \"\"))\n\n#covid-population join\ncovid_pop &lt;- left_join(data, pop, by = NULL)\n\nJoining with `by = join_by(county, state, fips)`\n\n#COVID/Population data to only include the last 14 days for 100k people\n\nlast_14_per100k &lt;- covid_pop %&gt;%\n  filter(date &gt;= (max(date)-14)) %&gt;% \n  group_by(fips, date) %&gt;%\n  mutate(new_perpop = new_cases/POPESTIMATE2021) %&gt;% \n  group_by(fips) %&gt;% \n  summarize(new_casesper100k = sum(new_perpop)*1e5, cumulative_cases = max(cases), county = first(county), state = first(state), na.rm = TRUE) %&gt;%\nungroup()\n\n###National Top 5 Counties with highest new case count in the last 14 days and number of counties meeting watchlist conditions\n\n#top 5 counties\n\nlast_14_per100k %&gt;% \n  slice_max(new_casesper100k, n = 5) %&gt;% \n  flextable()\n\nfipsnew_casesper100kcumulative_casescountystatena.rm4830118,518.519196LovingTexasTRUE290893,430.2612,515HowardMissouriTRUE290713,016.89325,852FranklinMissouriTRUE550782,024.6681,987MenomineeWisconsinTRUE022301,743.679187Skagway MunicipalityAlaskaTRUE\n\n#number of counties meeting the watch list condition\n\nlast_14_per100k %&gt;% \n  filter(new_casesper100k &gt; 100) %&gt;% nrow()\n\n[1] 1773\n\n\n1773 counties in the United States meet the watchlist condition of greater than 100 cases per 100k residents in the last 14 days.\n\n\n\nQ5: Death Toll\nGiven we are assuming it is February 1st, 2022. Your leadership has asked you to determine what percentage of deaths in each county were attributed to COVID last year (2021). You eagerly tell them that with the current Census data, you can do this!\nFrom previous questions you should have a data.frame with daily COVID deaths in Colorado and the Census based, 2021 total deaths. For this question, you will find the ratio of total COVID deaths per county (2021) of all recorded deaths. In a plot of your choosing, visualize all counties where COVID deaths account for 20% or more of the annual death toll.\n\n# Percentage of deaths that were due to COVID in 2021 for each county will require the population data and the covid cases data. We're going to use CO_Covid_pop for this and filter the year to 2021. \n#Variables:\n#DEATHS2021\n#deaths\n\n#create an object that represents deaths from just the year 2021\n\n\nco_covid_pop &lt;- co_covid_pop %&gt;% \n  mutate(year = lubridate::year(date))\n           \n\ndeaths_2021 &lt;- co_covid_pop %&gt;% \n  group_by(county) %&gt;%\n  filter(date == \"2021-12-31\") %&gt;% \n  mutate(deaths_2021 = deaths) %&gt;% \n  select(deaths_2021, county)\n\ndeaths_2020 &lt;- co_covid_pop %&gt;% \n  group_by(county) %&gt;% \n  filter(date == \"2020-12-31\") %&gt;% \n  mutate(deaths_2020 = deaths) %&gt;% \n  select(deaths_2020, county)\n\ncov_death_2021 &lt;- co_covid_pop %&gt;%\n  select(DEATHS2021, county, date) %&gt;%\n  filter(date == \"2021-12-31\") %&gt;% \n  group_by(county) %&gt;%\n  right_join(deaths_2020) %&gt;%\n  right_join(deaths_2021) %&gt;%\n  group_by(county) %&gt;% \n  mutate(deaths_2021_only = deaths_2021-deaths_2020) %&gt;%\n  mutate(cov_death_percent = (deaths_2021_only/DEATHS2021)*100) %&gt;% \n  select(deaths_2021_only, cov_death_percent) %&gt;%  filter(cov_death_percent &gt;= 20)\n\nJoining with `by = join_by(county)`\nJoining with `by = join_by(county)`\nAdding missing grouping variables: `county`\n\n\n\nMaking the graph\n\nggplot(data = cov_death_2021,\n       aes(x = county, y = cov_death_percent)) +\n       geom_bar(stat = \"Identity\", fill = \"steelblue\") +\n  coord_flip() +\n  theme_minimal()+\n  labs(\n    x = \"County Name\",\n    y = \"Percent of Deaths Attributed to COVID\",\n    title = \"CO Counties with Highest Percentage of\\nDeaths due to COVID in 2021\"\n  ) +\n  theme (plot.title = element_text(size = 11, hjust = .1, lineheight = 1.2, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nQ6: Multi-state\nIn this question, we are going to look at the story of 4 states and the impact scale can have on data interpretation. The states include: New York, Colorado, Alabama, and Ohio. Your task is to make a faceted bar plot showing the number of daily, new cases at the state level.\n\nFirst, we need to group/summarize our county level data to the state level, filter it to the four states of interest, and calculate the number of daily new cases (diff/lag) and the 7-day rolling mean.\n\n\ncovid_state &lt;- data %&gt;%\n  group_by(date, state) %&gt;% \n  summarize(cases = sum(cases)) %&gt;% #this makes each state have a cumulative case count for each day instead of separating it by county\n  filter(state %in% c(\"New York\", \"Colorado\", \"Alabama\", \"Ohio\")) %&gt;% #new cases grouped together by state\n  group_by(state) %&gt;% #had to group by state again because we just summarized\n  mutate(new_cases = cases - lag(cases)) %&gt;% \n  mutate(roll = zoo::rollmean(new_cases, k = 7, align = \"right\", fill = NA, na.rm = TRUE)) %&gt;% \n    #k is the size being averaged, align is where those values are relative to the reference, fill is for the beginning and end of the dataset, where there are no additional numbers to average\n  ungroup()\n\n`summarise()` has grouped output by 'date'. You can override using the\n`.groups` argument.\n\n  #makes a data.frame with new cases for each day in the whole state#ensures grouping by state continues in this dataframe\n\n\nUsing the modified data, make a facet plot of the daily new cases and the 7-day rolling mean. Your plot should use compelling geoms, labels, colors, and themes.\n\n\nggplot(covid_state, aes(x = date), na.rm = TRUE) +\ngeom_col(aes(y = new_cases), fill = \"pink\", col = NA) +#adds bar charts to represent the daily new COVID-19 cases. The height of each bar is determined by the newCases variable. The bars are filled with pink, and col = NA removes any border color from the bars.\n geom_line(aes(y = roll), col = \"darkred\", linewidth = 1) + # Overlays a line plot on the bars, representing the 7-day rolling average of new cases. The line is colored dark red and has a width of 1 for better visibility.\n  theme_linedraw() + #applies a clean, simple theme with black axis lines and minimal distractions.\n  facet_wrap(~state, nrow = 2, scales = \"fixed\") + # creates separate plots for each state using facet wrapping.    The nrow = 2 argument arranges the plots in two rows. The scales = \"free_y\" setting allows each state's y-axis to be independently scaled, preventing small-case states from being overshadowed by larger-case states \nggtitle(\"Cumulative COVID-19 Cases\") + xlab(\"Date\") +\n  ylab(\"Case Count\") + # adds a title and labels for the x and y axes. The title describes the plot, while the x-axis represents the date, and the y-axis represents the number of cases\n   theme (plot.title = element_text(size = 11, hjust = .5, lineheight = 1.2, face = \"bold\"), axis.text.x = element_text(angle = 45, hjust = 1, size = 7), axis.text.y = element_text(hjust = 1, size = 7))\n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_col()`).\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n# In R, when adding layers or components to a plot, each + should be on the same line as the previous part of the plot, not as a new statement.\n\n\nThe story of raw case counts can be misleading. To understand why, lets explore the cases per capita of each state. To do this, join the state COVID data to the population estimates and calculate the new cases/ total population. Additionally, calculate the 7-day rolling mean of the new cases per capita counts. This is a tricky task and will take some thought, time, and modification to existing code (most likely)!\n\n\nstate_pops &lt;- pop21 %&gt;% \n  mutate(state = STNAME) %&gt;% \n  filter(state %in% c(\"New York\", \"Colorado\", \"Alabama\", \"Ohio\")) %&gt;% \n  group_by(state) %&gt;% \n  summarize(population = sum(POPESTIMATE2021))\n\n\nstate_case_percap &lt;- data %&gt;% \n  filter(state %in% c(\"New York\", \"Colorado\", \"Alabama\", \"Ohio\")) %&gt;%\n  group_by(date, state) %&gt;%\n  select(state, date, county, cases, deaths) %&gt;%\n  group_by(state, date) %&gt;% \n  summarize(sum_cases = sum(cases), state = first(state)) %&gt;% \n  left_join(state_pops) %&gt;% \n  mutate(percap = sum_cases/population) %&gt;% \n  arrange(state, date) %&gt;% \n  mutate(new_cases_percap = percap - lag(percap)) %&gt;% \n  mutate(new_cases = sum_cases-lag(sum_cases))%&gt;% \n  mutate(roll = zoo::rollmean(new_cases_percap, k = 7, align = \"right\", fill = NA, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\nJoining with `by = join_by(state)`\n\n\n\nUsing the per capita data, plot the 7-day rolling averages overlying each other (one plot) with compelling labels, colors, and theme.\n\n\nggplot(state_case_percap, aes(x = date), na.rm = TRUE) +\ngeom_col(aes(y = new_cases_percap), fill = \"pink\", col = NA) +\n geom_line(aes(y = roll), col = \"darkred\", linewidth = 1) +\n  theme_linedraw() +\n  facet_wrap(~state, nrow = 2, scales = \"fixed\") +\nggtitle(\"Cumulative COVID-19 Cases Per Capita\") + xlab(\"Date\") +\n  ylab(\"Case Count Per Capita\") +\n   theme (plot.title = element_text(size = 11, hjust = .5, lineheight = 1.2, face = \"bold\"), axis.text.x = element_text(angle = 45, hjust = 1, size = 7), axis.text.y = element_text(hjust = 1, size = 7))\n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_col()`).\n\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\nBriefly describe the influence scaling by population had on the analysis? Does it make some states look better? Some worse? How so?\n\n\nQ6 Response\nAfter scaling the covid case data to a per capita basis, the states looked much more similar, eliminating some of the bias against larger states. Alabama’s peak looks more prominent, while New York’s peak around the same time looks less so.\n#Q7: Space & Time\nFor our final task, we will explore our first spatial example! In it we will calculate the Weighted Mean Center of the COVID-19 outbreak in the USA to better understand the movement of the virus through time.\nTo do this, we need to join the COVID data with location information. I have staged the latitude and longitude of county centers on the website.\n\ncounty_centroids &lt;- read_csv('https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv')\n\nRows: 3221 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): fips\ndbl (2): LON, LAT\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeta &lt;- county_centroids %&gt;% \n  inner_join(covid_pop) %&gt;%\n  group_by(date) %&gt;% \n  summarize(\n    wmX_c = sum(LON*cases / sum(cases)),\n    wmY_c = sum(LAT*cases / sum(cases)),\n  cases = sum(cases)) %&gt;% \n  arrange(date) %&gt;% \n  mutate(d = 1:n())\n\nJoining with `by = join_by(fips)`\n\nlibrary(ggplot2)\n\n# Check if 'meta' data exists and has the required columns\nif (!all(c(\"wmX_c\", \"wmY_c\", \"cases\", \"date\") %in% colnames(meta))) {\n  stop(\"The 'meta' data frame is missing required columns.\")\n}\n\n# Create the plot\nusa_case_map &lt;- ggplot(meta) +\n  borders(\"state\", fill = \"gray90\", color = \"white\") +\n  geom_point(aes(x = wmX_c, y = wmY_c, size = cases, color = format(date, \"%m\")), alpha = 0.7) +\n  theme_linedraw() +\n  labs(color = \"Month\", size = \"Cases\", x = \"\", y = \"\", title = \"Weighted Center of COVID-19 Cases\") +\n  theme(legend.position = \"bottom\")\n\nWarning: Duplicated aesthetics after name standardisation: colour\n\n# Verify if the plot object is created correctly\nprint(usa_case_map)  # Print the plot to the default device (screen)\n\n\n\n\n\n\n\n# Open the PDF device\npdf(\"usa_case_map.pdf\", width = 10, height = 7)  # Adjust dimensions as needed\n\n# Explicitly print the plot to the PDF device\nprint(usa_case_map)\n\n# Close the PDF device\ndev.off()\n\npng \n  2 \n\n#•  Loads county centroid data, which includes longitude and latitude coordinates for each county.\n#•  Joins this dataset with COVID-19 case data using county FIPS codes to match case data with county locations.\n#•  Groups the data by date and computes the weighted mean center of cases based on county coordinates and reported cases.\n#•  Orders the data chronologically and adds a time index to facilitate time-series visualization.\n#•  Creates a U.S. map as a background for plotting.\n#•  Plots the weighted mean center of COVID-19 cases for each day as a red dot, with larger dots representing higher case counts.\n#•  Uses a minimalistic theme to keep the visualization clean and readable.\n#•  Removes unnecessary legends to avoid clutter.\n\nPlease read in the data (readr::read_csv()); and join it to your raw COVID-19 data using the fips attributes using the URL.\nThe mean center of a set of spatial points is defined as the average X and Y coordinate. A weighted mean center can be found by weighting the coordinates by another variable, in this total cases such that:\nFor each date, calculate the Weighted Mean and using the daily cumulative cases and the weight . In addition, calculate the total cases for each day, as well as the month.\nHint: the month can be extracted from the date column using format(date, “%m”)\nPlot the weighted mean center (aes(x = LNG, y = LAT)), colored by month, and sized by total cases for each day. These points should be plotted over a map of the USA states which can be added to a ggplot object with:\n(feel free to modify fill and colour (must be colour (see documentation)))\n\n\nQ7 response\nIn a few sentences, describe the movement of the COVID-19 weighted mean throughout the USA and possible drivers of its movement given your knowledge of the outbreak hot spots.\nThe COVID-19 Weighted mean started out further west, where some of the early cases were reported, in the earlier months of the outbreak. As cases rapidly spread across the country and to larger cities like New York, the weighted center of cases moved closer to the center of the country. This graph is a bit misleading because on first glance it looks like the center of the US is representative of where the most cases are when in reality, most of the cases are in large population centers to the west, east, and south.\n\n\n\nQ8: Cases vs. Deaths\nAs extra credit, extend your analysis in problem three to also compute the weighted mean center of daily COVID deaths.\nMake two plots next to each other (using patchwork) showing cases in red and deaths in navy. Once completed describe the differences in the plots and what they mean about the spatial patterns seen with COVID impacts. (see guide on website)\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Create your first plot\nusa_case_map &lt;- ggplot(meta) +\n  borders(\"state\", fill = \"gray90\", colour =\"white\") +\n  geom_point(aes(x = wmX_c, y = wmY_c, size = cases, color = format(date, \"%m\")), alpha = 0.7) +\n  theme_linedraw() +\n  labs(size = \"Cases\", x = \"\", y = \"\", title = \"Weighted Center of COVID-19 Cases\", color = \"Month\") +\n  theme(legend.position = \"bottom\")\n\n# Verify if the plot object is created correctly\nprint(usa_case_map)  # Print the plot to the default device (screen)\n\n\n\n\n\n\n\n# Open the PDF device\npdf(\"usa_case_map.pdf\", width = 10, height = 7)  # Adjust dimensions as needed\n\n# Explicitly print the plot to the PDF device\nprint(usa_case_map)\n\n# Close the PDF device\ndev.off()\n\npng \n  2 \n\nmeta2 &lt;- county_centroids %&gt;% \n  inner_join(covid_pop) %&gt;%\n  group_by(date) %&gt;% \n  summarize(\n    wmX_c = sum(LON*deaths / sum(deaths)),\n    wmY_c = sum(LAT*deaths / sum(deaths)),\n    deaths = sum(deaths)) %&gt;% \n  arrange(date) %&gt;% \n  mutate(d = 1:n())\n\nJoining with `by = join_by(fips)`\n\n# Create your second plot\nusa_death_map &lt;- ggplot(meta2) +\n  borders(\"state\", fill = \"gray90\", colour =\"white\") +\n  geom_point(aes(x = wmX_c, y = wmY_c, size = deaths, color = format(date,\"%m\")), alpha = 0.7) +\n  theme_linedraw() +\n  labs(size = \"Deaths\", x = \"\", y = \"\", title = \"Weighted Center of COVID-19 Deaths\", color = \"Month\") +\n  theme(legend.position = \"bottom\")\n\nprint(usa_death_map)\n\nWarning: Removed 778 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n# Open the PDF device to save the plots\npdf(\"usa_case_maps_patchwork.pdf\", width = 5, height = 8)\n\n# Combine the plots vertically using patchwork's | operator\nusa_case_map / usa_death_map  # Use '/' to stack plots vertically\n\nWarning: Removed 778 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\nlibrary(htmltools)\ntags$iframe(src = \"C:/Users/Joshua Puyear/Documents/csu-undergrad/ess-330-joshp-2025/github/ess-330-labs/csu-ess-lab3/usa_case_maps_patchwork.pdf\", width = \"100%\", height = \"600px\")\n\n\n\n\n\nQ8 Response\nThe cases map is a much more scattered arrangement as multiple population centers were experiencing rapid rises in cases. The number of deaths is a relatively clear line from west to east. The median age of the eastern united states is slightly higher and with a greater population density (so more opportunities for cases to appear) and we know that older populations are more likely to succumb to the disease than younger people are."
  }
]